include "ndarray.nhp"

class matrix:
	ndarray<dec> buffer
	int rows
	int cols
	
	def __init__(ndarray<dec> buffer):
		assert buffer.dims as int == 2
		self.buffer = buffer
		rows = buffer.dims[0]
		cols = buffer.dims[1]
	
	def get(int r, int c) dec:
		return self.buffer.get([r - 1, c - 1])
	def set(int r, int c, dec elem) dec:
		return self.buffer.set([r - 1, c - 1], elem)
	
	def transpose():
		buffer = new ndarray<dec>([cols, rows], 0)
		i = 0
		while i < self.rows:
			j = 0
			while j < self.cols:
				buffer.set([j, i], self.buffer.get([i, j]))
				j = j + 1
			i = i + 1
		return new matrix(buffer)
	def minor(int r, int c) matrix:
		buffer = new ndarray<dec>([rows - 1, cols - 1], 0)
		i = 0
		k = 0
		while i < self.rows:
			if i != r - 1:
				j = 0
				l = 0
				while j < self.cols:
					if j != c - 1:
						buffer.set([k, l], self.buffer.get([i, j]))
						l = l + 1
					j = j + 1
				k = k + 1
			i = i + 1
		return new matrix(buffer)
	def det():
		assert self.rows == self.cols
		if self.rows == 2: #2x2 base case
			return (self.buffer.get([0, 0]) * self.buffer.get([1, 1])) - (self.buffer.get([0, 1]) * self.buffer.get([1, 0]))
		accum = 0
		i = 0
		cminordet = minor(0, c).det()
		while i < self.cols:
			accum = accum + ((-1)^i) * self.buffer.get([0, i]) * cminordet
			i = i + 1
		return accum
	def cofactors() matrix:
		buffer = new ndarray<dec>([self.rows, self.rows])
		i = 0
	def inverse() matrix:
		assert self.rows == self.cols
		d = det()
		if self.rows == 2: #2x2 base case
			invbuffer = new ndarray<dec>([2, 2], 0)
			invbuffer.set([0, 0], self.buffer.get([1, 1]) / d)
			invbuffer.set([1, 1], self.buffer.get([0, 0]) / d)
			invbuffer.set([0, 1], -self.buffer.get([0, 1]) / d)
			invbuffer.set([1, 0], -self.buffer.get([1, 0]) / d)
			return new matrix(invbuffer)
		